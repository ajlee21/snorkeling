{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MUST RUN AT THE START OF EVERYTHING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "database_str = \"sqlite:///\" + os.environ['WORKINGPATH'] + \"/Database/epilepsy.db\"\n",
    "os.environ['SNORKELDB'] = database_str\n",
    "\n",
    "from snorkel import SnorkelSession\n",
    "session = SnorkelSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse the Pubmed Abstracts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below is designed to read and parse data gathered from pubtator. Pubtator outputs their annotated text in xml format, so that is the standard file format we are going to use. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from epilepsy_utils import XMLMultiDocPreprocessor\n",
    "import os\n",
    "working_path = os.environ['WORKINGPATH']\n",
    "xml_parser = XMLMultiDocPreprocessor(\n",
    "    path= working_path + '/Database/epilepsy_data.xml',\n",
    "    doc='.//document',\n",
    "    text='.//passage/text/text()',\n",
    "    id='.//id/text()')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from epilepsy_utils import Tagger\n",
    "from snorkel.parser import CorpusParser\n",
    "import os\n",
    "working_path = os.environ['WORKINGPATH']\n",
    "dg_tagger = Tagger(working_path + \"/Database/epilepsy_tags_shelve\")\n",
    "corpus_parser = CorpusParser(fn=dg_tagger.tag)\n",
    "%time corpus_parser.apply(list(xml_parser))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.models import Document, Sentence\n",
    "\n",
    "print \"Documents: \", session.query(Document).count()\n",
    "print \"Sentences: \", session.query(Sentence).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get each candidate relation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This block of code below is designed to gather and tag each sentence found. **Note**: This does include the title of each abstract."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "gene_list = pd.read_csv(\"epilepsy-genes.tsv\",sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#This is a quick divide the documents without checking if they have gold standard or not\n",
    "from snorkel.models import Document\n",
    "import tqdm\n",
    "import random\n",
    "\n",
    "random.seed(100)\n",
    "#Grab the sentences!!!\n",
    "train_sents,dev_sents,test_sents = set(),set(),set()\n",
    "docs = session.query(Document).all()\n",
    "for doc in tqdm.tqdm(docs):\n",
    "    for s in doc.sentences:\n",
    "        in_dev = True if random.random() * 100 < 50 else False\n",
    "        if 'Gene' in s.entity_types:\n",
    "            if \";\" in s.entity_cids[s.entity_types.index('Gene')]:\n",
    "                cand = s.entity_cids[s.entity_types.index('Gene')].split(\";\")[0]\n",
    "                cand = int(cand)\n",
    "            else:\n",
    "                cand = int(s.entity_cids[s.entity_types.index('Gene')])\n",
    "            if cand in set(gene_list[gene_list[\"testing\"] == 1][\"entrez_gene_id\"]):\n",
    "                test_sents.add(s)\n",
    "            else:\n",
    "                if in_dev:\n",
    "                    dev_sents.add(s)\n",
    "                else:\n",
    "                    train_sents.add(s)\n",
    "        else:\n",
    "            if in_dev:\n",
    "                dev_sents.add(s)\n",
    "            else:\n",
    "                train_sents.add(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print len(train_sents)\n",
    "print len(dev_sents)\n",
    "print len(test_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.models import candidate_subclass\n",
    "\n",
    "#This specifies that I want candidates that have a disease and gene mentioned in a given sentence\n",
    "DiseaseGene = candidate_subclass('DiseaseGene', ['Disease', 'Gene'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.candidates import PretaggedCandidateExtractor\n",
    "\n",
    "ce = PretaggedCandidateExtractor(DiseaseGene, ['Disease', 'Gene'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Get the candidates from my custom tagger and then print number of candidates found\n",
    "for k,sents in enumerate([train_sents,dev_sents,test_sents]):\n",
    "    ce.apply(sents,split=k)\n",
    "    print \"Number of Candidates: \", session.query(DiseaseGene).filter(DiseaseGene.split == k).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look at the Potential Candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The one cool thing about jupyter is that you can use this tool to look at candidates. Check it out after everything above has finished running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.viewer import SentenceNgramViewer\n",
    "\n",
    "candidates = session.query(DiseaseGene).filter(DiseaseGene.split==1)\n",
    "sv = SentenceNgramViewer(candidates, session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sv"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
