{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MUST RUN AT THE START OF EVERYTHING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "#import os\n",
    "#os.environ['SNORKELDB'] = 'sqlite:///pubmed.db'\n",
    "\n",
    "from snorkel import SnorkelSession\n",
    "session = SnorkelSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse the Pubmed Abstracts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below is designed to read and parse data gathered from pubtator. Pubtator outputs their annotated text in xml format, so that is the standard file format we are going to use. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.parser import XMLMultiDocPreprocessor\n",
    "\n",
    "xml_parser = XMLMultiDocPreprocessor(\n",
    "    path='../data/Epilepsy/epilepsy_data.xml',\n",
    "    doc='.//document',\n",
    "    text='.//passage/text/text()',\n",
    "    id='.//id/text()')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from epilepsy_utils import Tagger\n",
    "from snorkel.parser import CorpusParser\n",
    "\n",
    "dg_tagger = Tagger(\"../data/Epilepsy/epilepsy_tags.txt\")\n",
    "corpus_parser = CorpusParser(fn=dg_tagger.tag)\n",
    "%time corpus_parser.apply(list(xml_parser))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.models import Document, Sentence\n",
    "\n",
    "print \"Documents: \", session.query(Document).count()\n",
    "print \"Sentences: \", session.query(Sentence).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get each candidate relation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This block of code below is designed to gather and tag each sentence found. **Note**: This does include the title of each abstract."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.models import Sentence\n",
    "test = session.query(Sentence)\n",
    "print test[0].entity_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#This line is for loading pre-sorted labels\n",
    "#import cPickle\n",
    "#train_ids,dev_ids,test_ids = map(set,cPickle.load(open('data/Epilepsy/doc_ids.pkl','rb')))\n",
    "\n",
    "#This is a quick divide the documents without checking if they have gold standard or not\n",
    "from snorkel.models import Document\n",
    "ids = [doc.name for doc in session.query(Document)]\n",
    "train_ids,dev_ids,test_ids = ids[0:4333],ids[4333:8666],ids[8666:12999]\n",
    "\n",
    "#Grab the sentences!!!\n",
    "train_sents,dev_sents,test_sents = set(),set(),set()\n",
    "docs = session.query(Document).all()\n",
    "for doc in docs:\n",
    "    for s in doc.sentences:\n",
    "        if doc.name in train_ids:\n",
    "            train_sents.add(s)\n",
    "        elif doc.name in dev_ids:\n",
    "            dev_sents.add(s)\n",
    "        elif doc.name in test_ids:\n",
    "            test_sents.add(s)\n",
    "        else:\n",
    "            print \"FAIL\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.models import candidate_subclass\n",
    "\n",
    "#This specifies that I want candidates that have a disease and gene mentioned in a given sentence\n",
    "DiseaseGene = candidate_subclass('DiseaseGene', ['Disease', 'Gene'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.candidates import PretaggedCandidateExtractor\n",
    "\n",
    "ce = PretaggedCandidateExtractor(DiseaseGene, ['Disease', 'Gene'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Get the candidates from my custom tagger and then print number of candidates found\n",
    "for k,sents in enumerate([train_sents,dev_sents,test_sents]):\n",
    "    ce.apply(sents,split=k)\n",
    "    print \"Number of Candidates: \", session.query(DiseaseGene).filter(DiseaseGene.split == k).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look at the Potential Candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The one cool thing about jupyter is that you can use this tool to look at candidates. Check it out after everything above has finished running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.viewer import SentenceNgramViewer\n",
    "\n",
    "candidates = session.query(DiseaseGene).filter(DiseaseGene.split==0)\n",
    "sv = SentenceNgramViewer(candidates, session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sv"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
